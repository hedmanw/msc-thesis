\chapter{Background}
%Manual, unstructured merging is time-consuming, and possibly concerned with the wrong abstraction level (i.e., source code) with respect to variants, which could be error-prone \cite{mens2002}, \cite{apel2011}.

This chapter introduces revision control systems, followed by feature-oriented software development and software product line engineering concepts and challenges. After that, an introduction to projectional editing is given. The chapter concludes with a description of the intention language for variant integration, and the prototype variant integration tool using the language.

\section{Revision Control Systems}
A revision control system is used to manage the revisions and variants of a software system as it evolves over time. Revisions represent the state of the source code at a particular point in time, and are used as the basis for subsequent revisions. As such, revisions can evolve or develop in isolation or in interaction with other revisions, and any revision might have several different subrevisions. The operation of combining functionality from diverging revisions, by combining their changesets into a new revision, is known as \textit{merging}. A recurring problem is that whenever incompatible concurrent divergent changes have occurred, a merge \textit{conflict} arises, meaning that the system cannot infer which changes to apply because both are equally valid \cite{mens2002}, \cite{apel2011}, \cite{buckley2005}. In order to resolve this conflict, the task is delegated to the user.

Revision control systems can be divided into two classes: \textit{unstructured} revision control systems that operate on plain text; and \textit{structured} revision control systems that rely on structure and semantics of the document being stored in order to leverage this knowledge for merge conflict resolution \cite{mens2002}, \cite{apel2011}. The former has reached popularity due to being language independent; examples of such revision control systems include Git, Subversion, and CVS, while structured revision control systems are mainly of academic interest, since they are not language independent \cite{apel2011}. Apel et al. \cite{apel2011} introduce the concept of a \textit{semistructured} revision control system, and in particular the \textit{semistructured} merge, which combines the strengths of the two classes, while minimizing their inherent weaknesses.

\subsection{Merging}
Since separate development tasks are carried out in parallel by different developers concurrently, contemporary revision control systems are \textit{optimistic}, meaning that each developer can work on their own personal copy of a particular artifact \cite{mens2002}. In practice, this means that two different developers can change the same file at the same time. Merging is the process that occurs whenever parallel changes to the same file are reconciled to a new revision, combining the changes. In cases where the merging algorithm cannot infer how to apply the parallel changes because they conflict, the resolution task is delegated to the user. Contemporary revision control systems use three-way merging, which minimizes the number of conflicts that must be delegated, because evolution can be inferred \cite{mens2002}. The name three-way merge comes from its input of three revisions: the two revisions of the software artifact to be merged; and their common ancestor revision \cite{mens2002}. A two-way merge takes only the two revisions to be merged as input, meaning that all differences between the two artifacts must be reconciled manually by the user -- none can be inferred.

\subsection{Forks}
Historically, the term \textit{forking} had a negative connotation, signifying a community schism or split causing subsequent independent divergent development efforts \cite{stanciulescu2015}. Today, forking (creating a \textit{fork}, a clone or duplicate of an entire project) is an integral part of open-source software communities \cite{gousios2014pullreq}, \cite{stanciulescu2015}.
Forking is an explicit part of modern social revision control platforms, such as Github or Bitbucket \cite{gousios2015}. Making forks a first-class citizen enables traceability and facilitates forking as a part of a pull-based development model \cite{stanciulescu2015}. In this model, changes are propagated across the ecosystem dynamically, using \textit{pull requests} \cite{gousios2014pullreq}, \cite{gousios2015}, \cite{stanciulescu2015}. In projects that employ a pull-based development model, any individual can create a fork and apply their desired changes, locally and decentralized. To spread their changes, possibly back into the mainline, they submit a pull request, indicating to the mainline developers that they should consider pulling and integrating the fork, should the quality be sufficient. During the lifetime of the pull request, it is possible that evolution occurs on the mainline -- it is then up to the requester to maintain their changes compatible with the evolved mainline.

\section{Features and Variability}
This section explains the complicated relationship between variants, features, and variability. 

\subsection{FOSD and SPLE}
Feature-Oriented Software Development (FOSD) is a paradigm for constructing large-scale software systems \cite{apel2009overview}. In FOSD, features are first-class citizens of the implementation of a software system \cite{apel2009overview}. As such, a highly configurable system is composed of a set of enabled features, which constitute the resulting system. A Software Product Line (SPL) is the set of software systems that can be derived from a set of features. Both FOSD and Software Product Line Engineering (SPLE) enable systematic reuse of components \cite{apel2009overview}, \cite{antkiewicz2014flexible}, meaning that they alleviate the negative aspects of clone-and-own by consolidating features.

\subsection{What is a Feature?}
The definition of what a feature is can be viewed from the problem space or the solution space, as defined by Czarnecki and Eisenecker \cite{czarnecki2000generative}, where the problem space contains domain-specific abstractions that describe the requirements  and intended behavior of a software system, and the solution space contains implementation-oriented abstractions defining how those requirements are met and the behavior is implemented \cite{apel2009overview}. There is a mapping from the problem space onto the solution space. From the problem space viewpoint, a feature is defined as ``\textit{a prominent or distinctive user-visible aspect, quality, or characteristic of a software system or systems}'' \cite{kang1990feature}, whereas from the solution space, a feature is defined as ``\textit{a structure that extends and modifies the structure of a given program in order to satisfy a stakeholder's requirement, to implement and encapsulate a design decision, and to offer a configuration option}'' \cite{apel2008algebra}.
The common denominator of both types is that a feature is always a logical unit of a system, delineated from other parts of it. Numerous additional definitions of \textit{feature} in the literature on the spectrum from problem space to solution space are reported in \cite{apel2009overview} and \cite{berger2015feature}.

These theoretical definitions are complemented by contemporary industrial notions on what constitutes a feature in a recent empirical study by Berger et al. \cite{berger2015feature}. This study shows that the meaning of a feature also varies among companies, but underlines that features should be distinct and well-delineated units of the system. Additionally, in practitioner settings, the origins of features are closely related to the business of the company; features can be customer-specific changes to a product, or arise from a particular market demand \cite{berger2015feature}.

\subsection{Software Variants and Variability}
Variants of a software are created to fulfill different requirements in similar products \cite{antkiewicz2014flexible}, \cite{stanciulescu2015}. Conceptually, the source code is altered in some way, to achieve different behavior. From a feature-oriented perspective, one or more features can be grouped inside a variant, and in FOSD and SPLE, any product is defined in terms of the features it is composed of \cite{apel2009overview}. The fastest way to create a variant of a software system is to copy the entire source code and make the required changes. This strategy is known as \textit{clone-and-own}, where small-scale changes are made to a large-scale copy in order to create a new variant \cite{stanciulescu2015}.

Orthogonal to variability through clones stands integrated variability. By centralizing all variant code in one common repository, distinct variants are instead derived by composing features. In the source code, this is realized by language-level constructs guarding the feature code, meaning that behavior can be enabled or disabled at compile-time (C preprocessor \texttt{\#ifdef} statement) or runtime (regular if-statements, design patterns). The inclusion of a particular feature into a variant is dictated by an associated boolean \textit{presence condition}, enabling or disabling code based on the selected feature configuration. This also enables the possibility to compose variants with arbitrary features, as opposed to clone-and-own, which requires one cloned project for each variant.

There is a tradeoff between time effort and maintainability with respect to the two variability strategies. Clone-and-own has low initial costs, but does not scale due to the inherent impact on the maintainability of a large number of clones, since each new variant requires a new clone \cite{antkiewicz2014flexible}. An integrated platform, on the other hand, requires significant up-front commitment and investment into architecture and infrastructure enabling systematic reuse \cite{antkiewicz2014flexible}.

In the context of software ecosystems, a common manifestation of variants is forks, which are repository-scale clones of an original codebase, called the \textit{mainline}. For forked variants, the variability lies in an array of repository clones with minor changes in them, altering the desired behavior. Using pull requests, the features within forks can be propagated across the ecosystem, integrated or adapted by others or become part of the mainline \cite{stanciulescu2015}, using a pull-based development model \cite{gousios2014pullreq}. The open-source 3D-printer firmware project \marlin~uses both forks (clone-and-own) and integrated variability (features using \texttt{\#ifdef}s) in parallel \cite{stanciulescu2015}, meaning that it can be used to study features originating in forks (cloned variants), being integrated into the mainline with variability.

\subsection{Platform Re-engineering}
A recent mapping study on the topic of re-engineering legacy applications into SPLs by Assun{\c{c}}{\~a}o et al. identifies 119 publications in the field \cite{assuncao2017mapping}. Most of these focus on variant detection and analysis to facilitate feature identification and feature location within systems, which is a prerequisite for moving from clone-and-own to an integrated platform. Antkiewicz et al. \cite{antkiewicz2014flexible} propose a strategy for migration from clone-and-own with low-risk, step-by-step adaption of an integrated platform through what they call \textit{virtual platform}. 

Using the terminology of Buckley et al. \cite{buckley2005}, cloned variants represent divergent changes being developed asynchronously in parallel \cite{mens2002}, \cite{stanciulescu2015}. Integrating forked variants back into an integrated mainline platform (analogue to migrating from clone-and-own to integrated platform) has the advantages of increased maintainability; features and bug-fixes being consolidated; and reducing unintentional code duplications \cite{schmorleiz2016similarity}, \cite{stanciulescu2015}. Since forks are inherently decentralized with respect to both organization and actual code base, knowledge and effort can be lost if they are not circulated back into the ecosystem \cite{stanciulescu2015}, \cite{gousios2015}.
Currently, the process of integrating variants is based on manual unstructured merging, relying fully on the developer to create a semantically correct merge \cite{mens2002}, \cite{apel2011}. An open-source proxy for this is merging forks back into the mainline \change{in a pull-based development model \cite{gousios2014pullreq}, since the pull requests come from large scale-clones with small-scale changes.}

%Schmorleiz and Lämmel \cite{schmorleiz2016similarity} realize a naïve virtual platform by introducing a tool that analyzes and annotates changes across cloned-and-owned variants. As a way to manage similarity, code fragments are annotated with invariants that propagate to across fragment clones in all variants. Adherence to the invariants is either performed manually or automatically by their tool. Santos and Kulesza \cite{santos} investigate conflicts that arise from integration of evolved clones. In their study of a web-based Java system, the most prominent conflict type is indirect -- changes in the source system are in the call graph of other changes in the target system -- which they find is in line with the motivation for semistructured merging \cite{apel2011}.

%\subsection{SPL evolution patterns}
%Table \ref{tab:safeevo}: Safe evolution templates for SPLs from \cite{neves2011evolution}. Feature addition and removal patterns from %\cite{passos2016coevolution}. Also: \cite{stanciulescu2016concepts}.
%\begin{table}[ht]
%    \centering
%    \caption{Safe evolution templates for SPLs \cite{neves2011evolution}}
%    \label{tab:safeevo}
%    \begin{tabular}{c|l}
%    \hline
%        \textbf{\#} & \textbf{Name} \\\hline
%        1 & Split Asset \\
%        2 & Refine Asset \\
%        3 & Add New Optional Feature \\
%        4 & Add New Mandatory Feature \\
%        5 & Replace Feature Expression
%    \end{tabular}
%\end{table}

\section{Projectional Editing}
\change{Projectional editors differ from traditional parser-based editors in what is edited, and how.} A traditional editor operates on a text buffer, that is eventually parsed by a compiler, given that it contains well-formed syntax. A projectional editor, on the other hand, operates directly on an abstract syntax tree (AST), meaning that it does not have to be parsed \cite{voelter2014towards}. The benefit is that only legal tokens can be entered into a projectional editor -- it is impossible to achieve syntax errors, but the disadvantage is that navigation and manipulation of the AST structure can be unintuitive.

\change{When editing variational software, comprehension can be increased by viewing the source code of a subset of features, and filter out the source code of other features \cite{stanciulescu2016concepts}. In source code with annotated features (e.g., C preprocessor), issues with alignment arise because the hidden code still impacts the indentation hierarchy \cite{behringer2017peopl}. In a projectional editor, the rows can be placed with correct alignment, because there, the indentation is semantic rather than syntactic.}

However, the usability of projectional editors has long been questioned. Berger et al. \cite{berger2016mps} have previously conducted a controlled experiment using students and industrial developers, to determine their editing efficiency in the projectional editor Jetbrains MPS, compared to a traditional parser-based editor. The participants are given four simple programming tasks to complete by editing a provided program, transforming it into a solution. They find that with training, projectional text editing is in fact more efficient than parser-based text editing.

%St\u{a}nciulescu et al. \cite{stanciulescu2016concepts} demonstrate the benefit of a projection-based variation control system to alleviate the complexities of maintaining and evolving code with preprocessor annotations.

%A recurring problem with annotation-based variation control systems is that source code chunks are shown with misaligned indenting \cite{behringer2017peopl}. This is caused by the fact that such variation control systems hide code blocks based on annotations, without compensating in the indentation structure of dependent code blocks. Projectional editing solves this alignment issue, since AST nodes are indented based on context rather than whitespace characters in a text buffer.

\section{Intention-based Variant Integration}
Today, a developer performing a feature-related merge in a revision control system must make ad hoc decisions on the final result, with respect to presence conditions over source code \cite{stanciulescu2016concepts}. This means that the concern of the developer is at the source-code level, dealing with fundamental language constructs defining the presence conditions of particular code blocks. We note that feature integration is a concern on the architectural level, while the merge is performed line-by-line on the source-code level. The mismatch between the architectural concern and the abstraction level on which it is carried out ensures that the integration (or merge) process is time consuming and has a high risk of introducing defects. Because of the mental overhead involved in considering multiple variants and their control flow, variability-related code is more defect-prone. Previous studies show that variability is detrimental for program comprehension \cite{melo2016latin}, \cite{favre1997understanding}, \cite{ernst2002preprocessor}, \cite{abal2014variability}, \cite{medeiros2015preprocessor}, \cite{medeiros2013syntaxerrors}.

We propose to address the mismatch of abstraction levels by introducing a domain specific language (DSL) capturing the semantics of the feature integration. In particular, the language describes the outcome that the developer wants to achieve. Examples include ``keep this functionality'' or ``remove this functionality''. We subsequently refer to these concepts simply as the \textit{intentions} of the developer. Each intention carries a mapping to actual operations that are performed on the source code. The semantics of the intentions language ensures the integrity of the underlying code upon which operations are applied to. This intentions language is the basis for creating a tool to aid the integration process structurally \cite{mens2002}, \cite{apel2011}. With proper tool support, the integration process can become more efficient from time consumption, risk, and quality perspectives. Indeed, tool support has shown to reduce variability errors in previous studies \cite{ribeiro2014emergent}.

The intentions and their underlying transformations can be described using choice calculus, a formal notation for variational software, independent of programming language \cite{erwig2011choice}, \cite{walkingshaw2012choice}. In the implementation, this can be realized as conditional compilation (C preprocessor) or \todo{design patterns} design patterns (object-oriented languages). Intentions could also be mapped to the source-code operations identified by Stanciulescu et al. in \cite{stanciulescu2016concepts}.

Gousios et al. point out that an important improvement for the merging process is tool support in terms of work prioritization and estimated time for merging \cite{gousios2015}. Tool support for proper variant-aware integration is also a prerequisite for the capability of migrating cloned product lines to an integrated platform through the virtual platform approach \cite{antkiewicz2014flexible}.

The work on the intentions language and the prototype tool \tooln, built on top of Jetbrains MPS, has been carried out jointly between Max Lillack, Ștefan St\u{a}nciulescu, Wilhelm Hedman, Thorsten Berger, and Andrzej W\k{a}sowski, and is described in \cite{lillack2017intentions}. The intentions language is designed as a DSL for variant integration, the key concept of which is intentions. Intentions are inplace transformations on a variational AST. The complete formal definition of the intentions language is given in \cite{lillack2017intentions}. A recapitulation with visual examples of the intentions and the effect of their associated AST transformation is given in Appendix \ref{a:intentions}. In \tooln, the two variants being integrated are inlined into a single variational AST, with the differences between them wrapped in the presence condition \texttt{FORK}. An example is shown in Figure \ref{fig:incline-ast}. Subsequently, this inlined notation is used.


\colorlet{greencolor}{green!30}
\colorlet{bluecolor}{blue!30}
\colorlet{lyellow}{yellow!10}
\begin{figure}[t]%
\centering
\noindent\begin{minipage}{.40\textwidth}
\begin{lstlisting}[escapechar=!]{Name}
Variant: Mainline
#ifdef ULTIPANEL
  uint8_t lastEncoderBits;
  uint32_t encoderPosition;
  #if !\colorbox{bluecolor}{PIN\_EXISTS(SD\_DETECT)}!
    !\colorbox{bluecolor}{uint8\_t lcd\_sd\_status;}!
  #endif
#endif

menu_t cM = lcd_status_scrn;
!\colorbox{bluecolor}{bool ignore\_click = false;}!
\end{lstlisting}
\end{minipage}\qquad
\begin{minipage}{.40\textwidth}
\begin{lstlisting}[escapechar=!]{Name}
Variant: Fork
#ifdef ULTIPANEL
 uint8_t lastEncoderBits;
 !\colorbox{bluecolor}{int8\_t encoderDiff;}!
 uint32_t encoderPosition;
 #if !\colorbox{bluecolor}{(SDCARDDETECT > 0)}!
  !\colorbox{bluecolor}{bool lcd\_oldcardstatus;}!
 #endif
#endif

menu_t cM = lcd_status_scrn;
\end{lstlisting}
\end{minipage}
\vspace{5mm}

\begin{minipage}{.40\textwidth}
\begin{lstlisting}[escapechar=!]
Variations inlined:
#ifdef ULTIPANEL
  uint8_t lastEncoderBits;
  #ifdef FORK
    int8_t encoderDiff;
  #endif
  uint32_t encoderPosition;
  #ifdef FORK
    #if SDCARDDETECT > 0
      bool lcd_oldcardstatus;
    #endif
  #else
    #if PIN_EXISTS(SD_DETECT)
      uint8_t lcd_sd_status;
    #endif
  #endif
#endif

menu_t cM = lcd_status_scrn;
#ifndef FORK
 bool ignore_click = false;
#endif
\end{lstlisting}
\end{minipage}

    \caption{Upper row: variant sources with differences highlighted. Lower row: inlined variational AST of the same variants in \tooln, with presence condition \texttt{FORK}. Example adapted from \cite{lillack2017intentions}.}
    \label{fig:incline-ast}
\end{figure}
