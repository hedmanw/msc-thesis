\chapter{Introduction}
Highly configurable software systems stem from the need of adapting software to fit different hardware or to meet specific customer demands. Such software systems can be developed in two orthogonal strategies: \textit{clone-and-own}, and \textit{integrated platform}. Clone-and-own is a quick and simple approach to create new variants of software, by cloning the entire source code of a project and making the required small-scale changes. The integrated platform approach instead offers systematic reuse, but requires significant engineering effort to adopt, which is costly. When the number of clones in a clone-and-own setting spirals out of control, the cloned variants must be re-engineered into a single integrated platform from which the variants can be derived. By adopting an integrated platform, maintainability can be increased and duplication of effort reduced \cite{schmorleiz2016similarity}, \cite{stanciulescu2015}.

The re-engineering process of variant integration, going from clone-and-own to integrated platform, is typically performed using revision control systems and diff tools, meaning that practitioners undertake the task similar to the task of software merging. The developer performing the merge must manually handle both the variability and potential conflicts on a source code level \cite{mens2002}, \cite{apel2011}, while features are in fact an architectural concern. This mismatch of abstraction levels means that feature integration is a complex task, and performing it manually is time-consuming and error-prone \cite{melo2016latin}. Understanding the patterns of such conflict resolution and variability management, and abstracting it away from the source code, considering the \textit{intentions} of the developer, allows for development of variability-aware integration tools. We show that the benefits of such a variability-aware integration tool is increased work speed and a reduced number variability-related defects.

This study evaluates a prototype variability-aware variant integration tool, called \tooln, based on a novel domain specific language (DSL) for specifying the integration goal in terms of so-called intentions.
The domain specific language is validated based on data obtained from mining the open-source 3D-printer firmware \marlin. Based on this, the tool prototype is extended and refined. Using a controlled experiment, the prototype tool is evaluated comparing it to an unstructured two-way diff tool, using variant integration tasks sampled from the UNIX utilities distribution \busybox~and the text editor \vim.

The following research questions are investigated:

\newcommand{\RQA}{Does the set of intentions suffice for variant integration?}
\newcommand{\RQB}{Is there a benefit over manual integration with a diff tool?}
\newcommand{\RQC}{How is the integration process different using the intention-based integration tool?}

\begin{enumerate}[label={Q\arabic*}]

        \item\label{rq-a} \textbf{Completeness:} \textit{\RQA}~We perform this verification step in order to assert that the intentions language can be instantiated to capture actual witnessed merges from real scenarios. This seeks to establish the completeness of the language.

        \item\label{rq-b} \textbf{Efficiency:} \textit{\RQB}~Our goal is that time effort, required edit operations, and code quality can be improved by a workflow incorporating the intention-based integration tool, which we summarize as the overall beneficence of the tool.\\
        We conjecture that a workflow with \tooln~is more efficient than a manual workflow.
        
        \item\label{rq-c} \textbf{Qualitative differences:} \textit{\RQC}~This is an investigation into the perceived and evident qualitative differences of the two integration approaches.
        
\end{enumerate}

To answer the research questions, we first mine highly configurable open source systems for variant integration merges, and analyze them to show that the intentions are capable expressing the witnessed merges, meaning that they are complete (Q1). We then perform a controlled experiment using students, measuring their editing efficiency and defects introduced when integrating variants in Eclipse CDT and \tooln~(Q2). The qualitative differences between unstructured integration and intention-based integration are elicited from participants in the controlled experiment using semi-structured interviews and questionnaires (Q3).

This thesis contributes:
\begin{itemize}
    \item a dataset of variability-related merges from \marlin,
    \item data from a preliminary tool evaluation with three participants,
    \item empirical data on the variant integration using our prototype intention-based variant integration tool with 16 student participants, and
    \item a qualitative investigation into the differences between intention-based and manual variant integration
\end{itemize}

The thesis is structured as follows: Chapter 2 outlines the background and rationale of variant integration. The methodology for data collection and experiments is presented in Chapter 3. Chapter 4 contains the results from the data collection of variant integration examples. The results of the empirical evaluation is reported in Chapter 5. Chapter 6 contains a discussion on inferences and validity threats to the study. Chapter 7 concludes with an outlook on future work.

%\item [RQ 1:] \textit{To what extent do the intentions properly model and reflect the intentions as evidenced in actual merges?} 

%\item [RQ 2:] \textit{Is using the intention-based merge tool beneficial for merging variants?} \textit{To what degree does the intention-based merge tool facilitate correct merges?} \textit{How much faster is the merge process using the intention-based merge tool?} \\
%\textbf{Hypothesis 1:} Using the intention-based merge tool leads to fewer bugs than manual merging.\\
%\textbf{Hypothesis 2:} Using the intention-based merge tool gives faster merging.
